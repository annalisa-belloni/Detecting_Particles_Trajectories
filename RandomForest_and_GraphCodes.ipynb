{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b3a02f-7af5-41f8-aba6-ba1a5d737671",
   "metadata": {},
   "source": [
    "# DSL Winter Project - RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c271e57-f339-4802-b5f1-a555669f2f8f",
   "metadata": {},
   "source": [
    "The following file, unlike the other \"ExtraTreesSolution\" provided, contains also the codes used to generate all the graphs presented in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b47165-859f-4a53-8533-5ce6feb1ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef845ca-5bbd-42d8-8e49-753e51230e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the random state\n",
    "rs = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db32b82-04fc-4413-972f-754a6ca0fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"development.csv\")\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff82c37a-f707-4095-a7da-a8348191034e",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad911b03-4f10-4005-be38-856a7fdab4ba",
   "metadata": {},
   "source": [
    "#### Domain constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b108ce7-6c30-4b6e-b76b-03d2747dad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(18):\n",
    "    mask = df_full[f'negpmax[{i}]']>0\n",
    "    df_full = df_full.loc[~mask]\n",
    "\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd3fcc-26c1-4219-8b30-fc59c99b3d84",
   "metadata": {},
   "source": [
    "### Detecting noise features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae438cb-182f-4c89-aecb-140832db0720",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "for i in range(18):\n",
    "    groups.append([f'pmax[{i}]', f'negpmax[{i}]', f'area[{i}]', f'tmax[{i}]', f'rms[{i}]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d078b8-cfc0-4350-b5d0-111a6031679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = df_full.copy()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for i, g in enumerate(groups):\n",
    "    group_features = df_pca[g]\n",
    "    \n",
    "    # standardize the features within the group\n",
    "    scaler = StandardScaler()\n",
    "    st_group_features = scaler.fit_transform(group_features)\n",
    "    \n",
    "    # apply PCA\n",
    "    pca = PCA(n_components=1)\n",
    "    pca_result = pca.fit_transform(st_group_features)\n",
    "    \n",
    "    # insert pca result into the copy of the df\n",
    "    df_pca[f\"pad_{i}\"] = pca_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f3d26-7420-4b9b-9a2d-05ab2a4ed1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pads = [ f'pad_{i}' for i in range(18)]\n",
    "sel = ['x', 'y']+pads\n",
    "\n",
    "df_pca = df_pca.loc[:,sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf2fd0-e67c-4287-b57c-e528deef1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cmap = sns.diverging_palette(145, 300, s=60, as_cmap=True)\n",
    "sns.heatmap(df_pca.corr(), cmap=custom_cmap)\n",
    "plt.savefig('pads_correlation.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0af954-5c50-49b7-9834-979c8e50fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_columns = [f\"pmax[{i}]\" for i in [0, 7, 12, 15, 16, 17]] + \\\n",
    "                [f\"negpmax[{i}]\" for i in [0, 7, 12, 15, 16, 17]] + \\\n",
    "                [f\"area[{i}]\" for i in [0, 7, 12, 15, 16, 17]] + \\\n",
    "                [f\"tmax[{i}]\" for i in [0, 7, 12, 15, 16, 17]] + \\\n",
    "                [f\"rms[{i}]\" for i in [0, 7, 12, 15, 16, 17]]\n",
    "noise_columns\n",
    "df_nonoise = df_full.drop(columns=noise_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582d6260-af06-42b5-90d7-9c0adb3d8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonoise['x'].corr(df_nonoise['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f969f46-9659-4709-bc30-61d885fdb517",
   "metadata": {},
   "source": [
    "### Investigating the features' importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abc4b6-f103-4cef-8b41-c27279e83912",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,4, figsize=(8,8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in zip([1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14], axes):\n",
    "    sc = ax.scatter(df_nonoise['x'], df_nonoise['y'], c=df_nonoise[f'pmax[{i}]'].values, alpha=0.2)\n",
    "    ax.set_title(f'pmax[{i}]',fontsize=10)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pmax_scatterbigger.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0dfcb4-3df3-4b01-8af1-5327f60c4355",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = df_nonoise.iloc[:,2:].corr()\n",
    "\n",
    "# correlation threshold\n",
    "corr_th = 0.9\n",
    "\n",
    "corr_pairs = []\n",
    "\n",
    "for i in range(len(corr_mat.columns)):\n",
    "    for j in range(i+1, len(corr_mat.columns)):\n",
    "        if abs(corr_mat.iloc[i, j]) > corr_th:\n",
    "            corr_pairs.append((corr_mat.columns[i], corr_mat.columns[j]))\n",
    "\n",
    "# Print the correlated variable pairs\n",
    "for pair in corr_pairs:\n",
    "    print(f\"Correlation between {pair[0]} and {pair[1]}: {corr_mat.loc[pair[0], pair[1]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21214d8-35b5-4364-847b-f5cbf608564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_nonoise\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb5040d-94bf-4f63-88b7-8c12768b6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing df in X (inputs) and y (target variables)\n",
    "y = df.loc[:,[\"x\", \"y\"]]\n",
    "X = df.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99fc82-9dbb-4ff7-b325-96599f2e9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True, stratify=y, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b89dfe-8bc4-46da-b5a2-a111bb97e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of the evaluation metric\n",
    "def euclidean_metric(y_true, y_pred):\n",
    "    return np.mean(np.sqrt(np.sum((y_true-y_pred)**2, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b0903e-b759-48bd-8b74-1827483d2826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "rf0 = RandomForestRegressor(n_estimators=100, random_state=rs, n_jobs=-1, verbose=5)\n",
    "rf0.fit(X_train, y_train)\n",
    "print(f\"r2: {r2_score(y_test, rf0.predict(X_test))} avg_euclidean:{euclidean_metric(y_test, rf0.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b61326-de63-4a3e-9d1f-ab48981e758b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_names = X.columns\n",
    "sorted(zip(feature_names, rf0.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "# It seems that tmax and rms are not important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb64cdce-f367-469b-8b5d-04f90669020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 13))\n",
    "feature_importance = pd.Series(rf0.feature_importances_, index = feature_names)\n",
    "feature_importance_sorted = feature_importance.sort_values(ascending=True)\n",
    "feature_importance_sorted.plot(kind='barh', logx=True)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel('Importance (log scale)') # --> in order to make results more readable on the graph\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importancelog.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a10ded-2f61-4f6a-8ca3-11abfb240410",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [f\"rms[{i}]\" for i in range(18) if i not in [0, 7, 12, 15, 16, 17]]\n",
    "t = [f\"tmax[{i}]\" for i in range(18) if i not in [0, 7, 12, 15, 16, 17]]\n",
    "# Remove rms and tmax\n",
    "c = r + t\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(columns=c), y, test_size=0.20, stratify=y, shuffle=True, random_state=rs)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814ce51-6d3e-419b-ae37-57c3d4f7c125",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c269c2-f86c-48b6-8c57-3df77920b4c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Trend of the performance in relation to n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c834a8d-36dc-49d3-9f6e-468e9cf7f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We took inspiration from the code provided on the website \" https://www.kaggle.com/code/ahmedabdulhamid/best-n-estimators-for-randomforest \" to plot the following graph.\n",
    "\n",
    "predictions = []\n",
    "for tree in rf1.estimators_:\n",
    "    predictions.append(tree.predict(X_test.values)[None, :])\n",
    "\n",
    "predictions = np.vstack(predictions)\n",
    "cum_mean = np.cumsum(predictions, axis=0)/np.arange(1, predictions.shape[0] + 1)[:, None, None]\n",
    "scores = []\n",
    "for pred in cum_mean:\n",
    "    scores.append(euclidean_metric(y_test, pred))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(scores, linewidth=3)\n",
    "plt.xlabel('Number of trees')\n",
    "plt.grid()\n",
    "plt.ylabel('Average euclidean distance')\n",
    "plt.savefig('num_of_trees.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628fbb8d-73e2-48d2-a6c9-911162e5ec7c",
   "metadata": {},
   "source": [
    "### RF - GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c8fb62-8e88-40c4-a29f-37d2fa88891d",
   "metadata": {},
   "source": [
    "Although we had already defined a validation test, we will now conduct a cross-validation, in order to be sure that we do not overfit a single subset of the _development_ set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef78b9e-2d42-4f74-a49f-3561e3342560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params_rf = {'n_estimators': [100, 200, 300],\n",
    "                  'max_features': [\"sqrt\", 0.33, 0.5],\n",
    "                  'criterion': [\"squared_error\", \"poisson\"],\n",
    "                  'n_jobs': [-1],\n",
    "                  'max_depth': [None, 10, 30, 50],\n",
    "                  'random_state': [rs]\n",
    "            }\n",
    "\n",
    "\n",
    "print(f\"start: {datetime.now()}\")\n",
    "gs_rf = GridSearchCV(RandomForestRegressor(), params_rf, scoring=make_scorer(euclidean_metric, greater_is_better=False),\n",
    "                          n_jobs=-1, cv=3, verbose=5)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "print(f\"end: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a1ee4-71a2-4aa1-9398-16ed32d2f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7558c07-8516-4773-8578-2495a02da143",
   "metadata": {},
   "source": [
    "{'criterion': 'squared_error', 'max_depth': None, 'max_features': 0.33, 'n_estimators': 300, 'n_jobs': -1, 'random_state': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdc6b0-a936-4034-837b-ed2ca794d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_rf.best_score_\n",
    "# -4.079161974683277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f3039-f9dc-4ffd-935b-844c0954583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_rf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8020a2-46a0-4b86-939d-037e17089fca",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a735513-3e2f-43c9-bb73-b6dd3002905b",
   "metadata": {},
   "source": [
    "### Result on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d25238-94d5-4969-9fa4-eafca10776b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"r2: {r2_score(y_test, gs_rf.predict(X_test))} avg_euclidean:{euclidean_metric(y_test, gs_rf.predict(X_test))}\") #---> optimal configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106343fa-c239-46cc-98af-ba0a48c6a041",
   "metadata": {},
   "source": [
    "### Conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4597c31c-68ca-4315-a2a2-fb7445407c11",
   "metadata": {},
   "source": [
    "**Final RandomForestRegressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b75e16-f4ae-44bf-ad50-ec06770f3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv(\"evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccafe47-095f-4fec-9e26-a04a61b50e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.drop(columns=noise_columns+c+['Id'], inplace=True) # drop noise, tmax, rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f07471-c6cf-40c3-9253-2a60bbf9943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_full.iloc[:,2:]\n",
    "y_full = df_full.loc[:,['x','y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63caff-0b2d-45b9-ab9f-880f2e49ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = X_full.drop(columns=noise_columns+c) # drop noise, tmax, rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5623378f-0011-4e84-b8ea-604c2bff630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "final_rf = RandomForestRegressor(n_estimators=300, max_features=0.33, criterion = 'squared_error', max_depth = None, random_state=rs, n_jobs=-1) #---> optimal configuration\n",
    "\n",
    "print(f\"start fitting: {datetime.now()}\")\n",
    "final_rf.fit(X_full, y_full)\n",
    "print(f\"end fitting: {datetime.now()}\")\n",
    "\n",
    "print(f\"start predicting: {datetime.now()}\")\n",
    "predictions = final_rf.predict(df_eval)\n",
    "print(f\"end predicting: {datetime.now()}\")\n",
    "\n",
    "data = {'Id': np.arange(0, predictions.shape[0]), 'Predicted': [f\"{val[0]}|{val[1]}\" for val in predictions]}\n",
    "submission = pd.DataFrame(data)\n",
    "submission.to_csv(\"output_rfFINAL.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
